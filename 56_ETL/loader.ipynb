{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serververbindung konfigurieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verbinden uns zur SQL Server Datenbank, die als Docker Container läuft. Zuvor wurde mit\n",
    "einem SQL Editor die Datenbank *Weatherdata* und das Schema aus [database.sql](database.sql) angelegt.\n",
    "Für das Beladen ist die Einstellung *fast_executemany* wichtig. \n",
    "\n",
    "> The cursor.executemany() function internally performs a loop and sends rows one by one, unless \n",
    "> “fast_executemany” flag is specified. If the flag is specified and if the drivers supports it, \n",
    "> the database will perform the operation (insert or update) on the entire array in a single operation.\n",
    "> (https://dbwhisperer.wordpress.com/2020/11/21/pyodbc-fast_executemany-and-oracle-rdbms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "connection_url = sqlalchemy.engine.URL.create(\n",
    "    \"mssql+pyodbc\",\n",
    "    username=\"sa\",\n",
    "    password=\"SqlServer2019\",      # oder ein anderes Passwort\n",
    "    host=\"127.0.0.1\",              # oder .\\SERVERNAME\n",
    "    database=\"Weatherdata\",\n",
    "    query={\n",
    "        \"driver\": \"ODBC Driver 17 for SQL Server\"\n",
    "    },\n",
    ")\n",
    "\n",
    "engine = sqlalchemy.create_engine(connection_url, fast_executemany=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leeren der Datenbank\n",
    "\n",
    "**Dies machen wir nur, damit alle den gleichen Ausgangszustand haben. Es kommt natürlich in echten\n",
    "Loaderskripts nicht vor dass die ganze Datenbank geleert wird!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE MeasurementDaily\")\n",
    "    conn.execute(\"TRUNCATE TABLE MeasurementHourly\")\n",
    "    conn.execute(\"DELETE FROM Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der originalen Meldungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit wir einen inkrementellen Import testen können, definieren wir eine Variable *max_year*. Die\n",
    "Messdaten umfassen die Jahre 2000 bis inklusive 2021. Zuerst importieren wir eine Teilmenge in die\n",
    "leere Datenbank. Danach setzen wir das Jahr auf 9999 und prüfen, ob wir nicht versehentlich doppelte\n",
    "Datensätze importieren. Das würde zu einem Fehler (UNIQUE Contraint) führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in den vorigen Beispielen laden wir die Stationsdaten aus den originalen Meldungen mit dem\n",
    "Synop Parser. Wir laden nur die Daten bis inklusive *max_year*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465962 Datensätze geladen.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>temp</th>\n",
       "      <th>dewp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>prec_duration</th>\n",
       "      <th>cloud_octas</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>sunshine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11082</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>997.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11082</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-01 03:00:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>998.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11082</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-01 06:00:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>998.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station       date            datetime  year  month  day  hour  minute  \\\n",
       "0    11082 2000-01-01 2000-01-01 00:00:00  2000      1    1     0       0   \n",
       "1    11082 2000-01-01 2000-01-01 03:00:00  2000      1    1     3       0   \n",
       "2    11082 2000-01-01 2000-01-01 06:00:00  2000      1    1     6       0   \n",
       "\n",
       "   temp  dewp  pressure  prec_amount  prec_duration  cloud_octas  wind_dir  \\\n",
       "0  -3.4  -5.3     997.7          NaN            NaN          NaN       9.0   \n",
       "1  -3.7  -5.3     998.4          NaN            NaN          NaN       3.0   \n",
       "2  -2.7  -4.1     998.8          NaN            NaN          NaN       0.0   \n",
       "\n",
       "   wind_speed  max_temp  min_temp  sunshine  \n",
       "0         1.0       NaN       NaN       NaN  \n",
       "1         1.0       NaN       NaN       NaN  \n",
       "2         0.0       NaN      -5.5       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import parseSynop as ps    # Datei parseSynop.py laden\n",
    "data_vienna_city = ps.readFile(\"synop_11034.txt.bz2\")  # Wien Innere Stadt\n",
    "data_vienna_hohewarte = ps.readFile(\"synop_11035.txt.bz2\")  # Wien Hohe Warte\n",
    "data_gump = ps.readFile(\"synop_11082.txt.bz2\")    # Gumpoldskirchen\n",
    "data_rax = ps.readFile(\"synop_11180.txt.bz2\")     # Rax Bergstation\n",
    "data = pd.concat([data_gump, data_vienna_city, data_vienna_hohewarte, data_rax])\n",
    "data = data[data.year <= max_year]\n",
    "print(f\"{len(data)} Datensätze geladen.\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden des Stationsverzeichnisses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf [www.zamg.ac.at](https://www.zamg.ac.at/cms/de/klima/messnetze/wetterstationen) kann eine CSV\n",
    "Datei mit den Wetterstationen geladen werden. Es ist die Basis für die Tabelle Station in unserer\n",
    "Datenbank. Daher laden wir diese Datei aus dem Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>BUNDESLAND</th>\n",
       "      <th>LÄNGE</th>\n",
       "      <th>BREITE</th>\n",
       "      <th>STATIONSHÖHE</th>\n",
       "      <th>BEGINNDATUM</th>\n",
       "      <th>ORDNUNG</th>\n",
       "      <th>LÄNGE DEZI</th>\n",
       "      <th>BREITE DEZI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYNNR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8989072</th>\n",
       "      <td>ANDAU</td>\n",
       "      <td>BGL</td>\n",
       "      <td>170200</td>\n",
       "      <td>474621</td>\n",
       "      <td>118</td>\n",
       "      <td>19950701</td>\n",
       "      <td>TAWES</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>47.772499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td>ANDAU NEU</td>\n",
       "      <td>BGL</td>\n",
       "      <td>170208</td>\n",
       "      <td>474612</td>\n",
       "      <td>117</td>\n",
       "      <td>20210616</td>\n",
       "      <td>TAWES/VAMES</td>\n",
       "      <td>17.035555</td>\n",
       "      <td>47.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>BAD TATZMANNSDORF</td>\n",
       "      <td>BGL</td>\n",
       "      <td>161330</td>\n",
       "      <td>472017</td>\n",
       "      <td>347</td>\n",
       "      <td>20040917</td>\n",
       "      <td>Ö3</td>\n",
       "      <td>16.224998</td>\n",
       "      <td>47.338055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       NAME BUNDESLAND   LÄNGE  BREITE  STATIONSHÖHE  \\\n",
       "SYNNR                                                                  \n",
       "8989072               ANDAU        BGL  170200  474621           118   \n",
       "11395             ANDAU NEU        BGL  170208  474612           117   \n",
       "11193    BAD TATZMANNSDORF         BGL  161330  472017           347   \n",
       "\n",
       "         BEGINNDATUM      ORDNUNG  LÄNGE DEZI  BREITE DEZI  \n",
       "SYNNR                                                       \n",
       "8989072     19950701        TAWES   17.033333    47.772499  \n",
       "11395       20210616  TAWES/VAMES   17.035555    47.770000  \n",
       "11193       20040917           Ö3   16.224998    47.338055  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_csv(\"https://www.zamg.ac.at/cms/de/dokumente/klima/dok_messnetze/Stationsliste_20220101.csv\", sep=\";\",\n",
    "    encoding=\"cp1252\", decimal=\",\", index_col=\"SYNNR\")\n",
    "\n",
    "stations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform und Filterung (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der 2. Schritt besteht aus zwei Teilen. Zuerst müssen wir die Daten in das Format der\n",
    "Zieltabelle transformieren. Dabei sind mehrere Schritte nötig:\n",
    "- Transformation von Fremdschlüssel\n",
    "- Umbenennung von Spalten\n",
    "\n",
    "Der zweite Teil filtert Daten aus:\n",
    "- Können alle Daten aufgrund der Datentypen und Constraints importiert werden?\n",
    "- Sind schon Werte in der Datenbank vorhanden, die ausgefiltert werden müssen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten für die Tabelle Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nur neu hinzugekommene Stationen in die Tabelle *Station* importieren. Dafür müssen\n",
    "wir uns eine Liste aller Stations-IDs von der Datenbank holen (*station_ids*). Die Bundesländer\n",
    "sind in der Datei der ZAMG mit eigenen Kürzeln angeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BGL', 'KNT', 'NOE', 'OOE', 'SAL', 'STMK', 'TIR', 'VBG', 'WIE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.BUNDESLAND.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In unserer Station Tabelle verweisen wir allerdings auf die Tabelle Bundesland mit einem eigenen\n",
    "(numerischen) Schlüssel. Die Tabelle *Bundesland* in der Datenbank hat folgende Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Shortname</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BGL</td>\n",
       "      <td>Burgenland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>KNT</td>\n",
       "      <td>Kärnten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NOE</td>\n",
       "      <td>Niederösterreich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>OOE</td>\n",
       "      <td>Oberösterreich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SAL</td>\n",
       "      <td>Salzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>STMK</td>\n",
       "      <td>Steiermark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>TIR</td>\n",
       "      <td>Tirol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>VBG</td>\n",
       "      <td>Vorarlberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>WIE</td>\n",
       "      <td>Wien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Shortname              Name\n",
       "0   1       BGL        Burgenland\n",
       "1   2       KNT           Kärnten\n",
       "2   3       NOE  Niederösterreich\n",
       "3   4       OOE    Oberösterreich\n",
       "4   5       SAL          Salzburg\n",
       "5   6      STMK        Steiermark\n",
       "6   7       TIR             Tirol\n",
       "7   8       VBG        Vorarlberg\n",
       "8   9       WIE              Wien"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with engine.connect() as conn: display(pd.read_sql(\"Bundesland\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir müssen also im Transform Prozess für die Stationen konkret 2 Schritte erledigen:\n",
    "- Die Stationen ausfiltern, dessen ID (*SYNNR* in der Datei) schon in der Datenbank ist.\n",
    "- Die Fremdschlüssel müssen wir von den Kurznamen auf die internen IDs der Datenbank ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Alt</th>\n",
       "      <th>BundeslandId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8989072</td>\n",
       "      <td>ANDAU</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>47.772499</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11395</td>\n",
       "      <td>ANDAU NEU</td>\n",
       "      <td>17.035555</td>\n",
       "      <td>47.770000</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11193</td>\n",
       "      <td>BAD TATZMANNSDORF</td>\n",
       "      <td>16.224998</td>\n",
       "      <td>47.338055</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                Name        Lng        Lat  Alt  BundeslandId\n",
       "0  8989072               ANDAU  17.033333  47.772499  118             1\n",
       "1    11395           ANDAU NEU  17.035555  47.770000  117             1\n",
       "2    11193  BAD TATZMANNSDORF   16.224998  47.338055  347             1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    station_ids = conn.execute(\"SELECT Id FROM Station\").all()\n",
    "    bundeslaender_db = conn.execute(\"SELECT Shortname, Id FROM Bundesland\").all()\n",
    "\n",
    "bundeslaender_db = {b[0]: b[1] for b in  bundeslaender_db} # Liste von Tupel mit 2 Elementen in ein Dictionary umwandeln\n",
    "station_ids = [s[0] for s in station_ids]                  # Liste von Tupel mit 1 Element in eine normale Liste umwandeln\n",
    "\n",
    "# Mit der relace() Methode des Dataframes können wir sehr einfach den Wert von Bundesland suchen\n",
    "# und den Wert im Dictionary bundeslaender_db eintragen:\n",
    "stations[\"BL_ID\"] = stations.BUNDESLAND.replace(bundeslaender_db)\n",
    "col_mapping={\"SYNNR\": \"Id\", \"NAME\": \"Name\", \"LÄNGE DEZI\": \"Lng\", \"BREITE DEZI\": \"Lat\", \"STATIONSHÖHE\": \"Alt\", \"BL_ID\": \"BundeslandId\"}\n",
    "# Nun filtern wir alle Datensätze aus stations, dessen indexwert (der Index von Stations ist die SYNNR)\n",
    "# nicht in der Liste station_ids ist. ~ bedeutet Negierung.\n",
    "stations_export = stations \\\n",
    "    .reset_index() \\\n",
    "    .loc[~stations.index.isin(station_ids), col_mapping.keys()].rename(columns=col_mapping)\n",
    "stations_export.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten für die Tabelle MeasurementHourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei den Daten der Tabelle *MeasurementHourly* müssen wir auf die Performace acht geben. Es sind\n",
    "ca. 500 000 Werte in der Tabelle. Wir dürfen Messwerte nicht erneut importieren, denn das würde\n",
    "zu einem Fehler beim Import führen. Daher müssen wir die in der Datenbank vorhandenen Werte\n",
    "ausschließen. \n",
    "\n",
    "Bei den Stationen haben wir einfach die Liste der ID Werte gelesen. Bei den Messwerten gibt es\n",
    "für StationId und Datetime ein UNIQUE Constraint. Wir könnten also diese beiden Werte laden und\n",
    "für jeden Wert im Dataframe prüfen, ob er schon vorhanden ist.\n",
    "\n",
    "Bei dieser Menge an Datensätzen würde das allerdings sehr lange dauern. Wir entscheiden uns daher\n",
    "für eine andere Lösung: Wir laden pro Station das Datum des letzten Eintrages. Das ist eine einfache\n",
    "MAX(Datetime) Abfrage und liefert pro Station einen Datensatz. Danach markieren wir im Dataframe\n",
    "die Daten, sodass pro Station nur Werte ab dem letzten Eintrag in der Datenbank geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465961 Datensätze zu importieren:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StationId\n",
       "11034    113526\n",
       "11035    117232\n",
       "11082    122105\n",
       "11180    113098\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "with engine.connect() as conn:\n",
    "    last_measurement_hourly = conn \\\n",
    "        .execute(\"SELECT StationId AS STATION_ID, MAX(Datetime) AS LAST_DATETIME FROM MeasurementHourly GROUP BY StationId\") \\\n",
    "        .all()\n",
    "# Ein Dictionary mit StationId: Letzter Messwert aus der Liste der Tupel, die uns all() lieferte, erzeugen.\n",
    "last_measurement_hourly = {m[0]: m[1] for m in  last_measurement_hourly}\n",
    "# Standardwert, falls eine Station noch gar nicht vorkommt.\n",
    "begin = dt.datetime(1900,1,1)\n",
    "# In der Tabelle sind Temperaturen zweistellig. Das ist auch ausreichend, es gibt aber durch Fehlwerte\n",
    "# Fälle, wo ein Komma nicht übertragen wurde. So wird aus 20.1° 201° im Datenbestand. Das filtern\n",
    "# wir aus.\n",
    "valid_values = (data.temp.abs() < 100) & (data.dewp.abs() < 100)\n",
    "# Wir holen uns mit get() die Station der Zeile und prüfen, ob das Datum nachher ist. Wird der key\n",
    "# nicht gefunden, wird begin als Defaultwert zurückgeliedert.\n",
    "new_values = data.apply(lambda row: row.datetime > last_measurement_hourly.get(row.station, begin), axis=1)\n",
    "# Mapping der Spalten Dataframe -> Tabelle\n",
    "col_mapping = {\"station\": \"StationId\", \"datetime\": \"Datetime\", \"temp\": \"Temp\", \"dewp\": \"Dewp\"}\n",
    "measurement_hourly = data.loc[valid_values & new_values, col_mapping.keys()].rename(columns=col_mapping)\n",
    "print(f\"{len(measurement_hourly)} Datensätze zu importieren:\")\n",
    "measurement_hourly.groupby(\"StationId\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden in die Tabelle Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    stations_export.to_sql(\"Station\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden in die Tabelle MeasurementHourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    measurement_hourly.to_sql(\"MeasurementHourly\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit SQL können wir die Anzahl der Werte aus der Datenbank lesen. Die Aggregierung macht die\n",
    "Datenbank. Für eine Ausgabe der Häufigkeiten die ganze Tabelle zu lesen und diese dann im DataFrame\n",
    "zu verarbeiten wäre Unsinn. SQL ist daher immer eine wichtige Technologie, die auch im DataScrience\n",
    "beherrscht werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StationId</th>\n",
       "      <th>11034</th>\n",
       "      <th>11035</th>\n",
       "      <th>11082</th>\n",
       "      <th>11180</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2843</td>\n",
       "      <td>3533</td>\n",
       "      <td>3342</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2599</td>\n",
       "      <td>2642</td>\n",
       "      <td>2597</td>\n",
       "      <td>2482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3934</td>\n",
       "      <td>3936</td>\n",
       "      <td>3934</td>\n",
       "      <td>3877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>8429</td>\n",
       "      <td>8518</td>\n",
       "      <td>8385</td>\n",
       "      <td>8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>7375</td>\n",
       "      <td>8410</td>\n",
       "      <td>7348</td>\n",
       "      <td>7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>6872</td>\n",
       "      <td>7895</td>\n",
       "      <td>6868</td>\n",
       "      <td>6307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2984</td>\n",
       "      <td>2952</td>\n",
       "      <td>2984</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2821</td>\n",
       "      <td>2919</td>\n",
       "      <td>2814</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2849</td>\n",
       "      <td>2911</td>\n",
       "      <td>2856</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2825</td>\n",
       "      <td>2918</td>\n",
       "      <td>2836</td>\n",
       "      <td>2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2836</td>\n",
       "      <td>2913</td>\n",
       "      <td>2843</td>\n",
       "      <td>2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2892</td>\n",
       "      <td>2920</td>\n",
       "      <td>2890</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>3016</td>\n",
       "      <td>3125</td>\n",
       "      <td>3018</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2685</td>\n",
       "      <td>2920</td>\n",
       "      <td>2687</td>\n",
       "      <td>2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2878</td>\n",
       "      <td>2919</td>\n",
       "      <td>5636</td>\n",
       "      <td>2877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>3271</td>\n",
       "      <td>3307</td>\n",
       "      <td>8606</td>\n",
       "      <td>3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>8774</td>\n",
       "      <td>8767</td>\n",
       "      <td>8774</td>\n",
       "      <td>8762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>8744</td>\n",
       "      <td>8753</td>\n",
       "      <td>8755</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>8680</td>\n",
       "      <td>8691</td>\n",
       "      <td>8663</td>\n",
       "      <td>8657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>8749</td>\n",
       "      <td>8753</td>\n",
       "      <td>8751</td>\n",
       "      <td>8754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>8723</td>\n",
       "      <td>8781</td>\n",
       "      <td>8768</td>\n",
       "      <td>8767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>8747</td>\n",
       "      <td>8749</td>\n",
       "      <td>8750</td>\n",
       "      <td>8752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count                  \n",
       "StationId 11034 11035 11082 11180\n",
       "Year                             \n",
       "2000       2843  3533  3342  3359\n",
       "2001       2599  2642  2597  2482\n",
       "2002       3934  3936  3934  3877\n",
       "2003       8429  8518  8385  8071\n",
       "2004       7375  8410  7348  7603\n",
       "2005       6872  7895  6868  6307\n",
       "2006       2984  2952  2984  2944\n",
       "2007       2821  2919  2814  2825\n",
       "2008       2849  2911  2856  2853\n",
       "2009       2825  2918  2836  2816\n",
       "2010       2836  2913  2843  2833\n",
       "2011       2892  2920  2890  2874\n",
       "2012       3016  3125  3018  3006\n",
       "2013       2685  2920  2687  2652\n",
       "2014       2878  2919  5636  2877\n",
       "2015       3271  3307  8606  3267\n",
       "2016       8774  8767  8774  8762\n",
       "2017       8744  8753  8755  8760\n",
       "2018       8680  8691  8663  8657\n",
       "2019       8749  8753  8751  8754\n",
       "2020       8723  8781  8768  8767\n",
       "2021       8747  8749  8750  8752"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with engine.connect() as conn: display(pd.read_sql(\"\"\"\n",
    "SELECT StationId, DATEPART(year, datetime) AS Year, COUNT(*) AS Count\n",
    "FROM MeasurementHourly\n",
    "GROUP BY StationId, DATEPART(year, datetime)\n",
    "\"\"\", conn).pivot(index=\"Year\", columns=\"StationId\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir zum Testen den Filter *max_year* auf 9999 stellen und prüfen, ob das Laden von\n",
    "neu hinzugekommenen Daten auch funktioniert."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bd13bc16400e16874b7ce28af58a129343287e94248a182c1f06fbb6b76ef8e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
